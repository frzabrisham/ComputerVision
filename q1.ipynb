{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNphZ45U9Epx1FBpeQ8acqh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frzabrisham/ComputerVision/blob/main/q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "XluDIZ1gKAvk",
        "outputId": "8b7e5b9e-1707-4eb5-985f-5a0c6063d815"
      },
      "source": [
        "import numpy as np\n",
        "from cv2 import *\n",
        "from numpy.linalg import inv\n",
        "\n",
        "folder = 'Frames/'\n",
        "path450 = folder + 'f0450.jpg'\n",
        "path270 = folder + 'f0270.jpg'\n",
        "path630 = folder + 'f0630.jpg'\n",
        "path90 = folder + 'f0090.jpg'\n",
        "path810 = folder + 'f0810.jpg'\n",
        "path1 = folder + 'f0001.jpg'\n",
        "\n",
        "img450, im450 = imread(path450), imread(path450)\n",
        "img270 = imread(path270)\n",
        "img630 = imread(path630)\n",
        "img90 = imread(path90)\n",
        "img810 = imread(path810)\n",
        "img1 = imread(path1)\n",
        "\n",
        "height = int(img450.shape[0])\n",
        "width = int(img450.shape[1])\n",
        "\n",
        "image_folder = os.fsencode(folder)\n",
        "filenames = []\n",
        "for file in os.listdir(image_folder):\n",
        "    filename = os.fsdecode(file)\n",
        "    if filename.endswith('.jpg'):\n",
        "        filenames.append(filename)\n",
        "\n",
        "filenames.sort()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6f3668c8da2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg450\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg450\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8F1NyY-lE8J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPVcAKeDKivz"
      },
      "source": [
        "در این قسمت از کد ایمپورت‌ها و خواندن عکس‌های کلیدی را انجام داده‌ام. هم‌چنین در \n",
        "\n",
        "filenames\n",
        "\n",
        "اسامی عکس‌های فریم‌ها را قرار داه‌ام. که در قسمت سوم سوال نیاز می‌شود."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "rzBchNHJKEOW",
        "outputId": "efc22019-84f1-4661-e8ea-a3f142631e64"
      },
      "source": [
        "\n",
        "sift = cv2.SIFT_create()\n",
        "\n",
        "FLANN_INDEX_KDTREE = 0\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "search_params = dict(checks=50)\n",
        "flann = FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "kp450, des450 = sift.detectAndCompute(img450, None)\n",
        "kp270, des270 = sift.detectAndCompute(img270, None)\n",
        "kp630, des630 = sift.detectAndCompute(img630, None)\n",
        "kp90, des90 = sift.detectAndCompute(img90, None)\n",
        "kp810, des810 = sift.detectAndCompute(img810, None)\n",
        "kp1, des1 = sift.detectAndCompute(img1, None)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-064c31c94021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mFLANN_INDEX_KDTREE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindex_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLANN_INDEX_KDTREE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'SIFT_create'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DIUfGE2KhQ-"
      },
      "source": [
        "در این قسمت ابتدا سیفت را تعریف کرده و \n",
        "\n",
        "keyPoints , descriptors\n",
        "\n",
        "را برای عکس‌های کلیدی حساب نمودم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raIBlfifKcYA"
      },
      "source": [
        "\n",
        "def matching(matches, kp_main, kp_min):\n",
        "    matched_main, matched = [], []\n",
        "    thresh = 0.6\n",
        "    for match in matches:\n",
        "        p1 = kp_main[match[0].queryIdx].pt\n",
        "        p2 = kp_min[match[0].trainIdx].pt\n",
        "\n",
        "        if match[0].distance < thresh * match[1].distance:\n",
        "            matched_main.append([p1])\n",
        "            matched.append([p2])\n",
        "\n",
        "    return matched_main, matched\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAKvt32DMDSC"
      },
      "source": [
        "در این تابع مچ‌پوینت‌های دو عکسی که قرار است هموگرافی‌ آن‌ها را دربیاوریم محاسبه کردم. \n",
        "\n",
        "\n",
        "kp_main\n",
        "\n",
        "نقاط عکسی است که هموگرافی به آن عکس را می‌خواهیم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XZxlurYMCVi"
      },
      "source": [
        "\n",
        "\n",
        "def find_hom(des_ref, des_minor, kp_ref, kp_minor):\n",
        "    matches = flann.knnMatch(des_ref, des_minor, k=2)\n",
        "    matched_1, matched_2 = matching(matches, kp_ref, kp_minor)\n",
        "    H, status = findHomography(np.array(matched_2), np.array(matched_1), RANSAC, maxIters=10000)\n",
        "    return H\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemSYuyEKgX8"
      },
      "source": [
        "در این قسمت دیسکریپتورها و کی‌پوینت‌های دو عکس را گرفته و هموگرافی به عکس مرجع را حساب می‌کنیم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBMFz-m_M-aQ"
      },
      "source": [
        "\n",
        "def corner(H):\n",
        "    t0 = H @ np.array([0, 0, 1])\n",
        "    t0 = t0 / t0[2]\n",
        "    t1 = H @ np.array([width - 1, 0, 1])\n",
        "    t1 = t1 / t1[2]\n",
        "    t2 = H @ np.array([0, height - 1, 1])\n",
        "    t2 = t2 / t2[2]\n",
        "    t3 = H @ np.array([width - 1, height - 1, 1])\n",
        "    t3 = t3 / t3[2]\n",
        "    return t0, t1, t2, t3\n",
        "\n",
        "\n",
        "def dim(H):\n",
        "    t0, t1, t2, t3 = corner(H)\n",
        "    x_cor = max(max(max(t0[0], t1[0]), t2[0]), t3[0])\n",
        "    y_cor = max(max(max(t0[1], t1[1]), t2[1]), t3[1])\n",
        "\n",
        "    return [int(x_cor[0][0]) + 100, int(y_cor[0][0]) + 100]\n",
        "\n",
        "\n",
        "def trans(H):\n",
        "    t0, t1, t2, t3 = corner(H)\n",
        "    x_cor = min(min(min(t0[0], t1[0]), t2[0]), t3[0])\n",
        "    y_cor = min(min(min(t0[1], t1[1]), t2[1]), t3[1])\n",
        "    p = [x_cor[0][0], y_cor[0][0]]\n",
        "    t = ([[1, 0, -p[0] + 200], [0, 1, -p[1] + 100], [0, 0, 1]])\n",
        "    return t\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trm0CpFxNHe4"
      },
      "source": [
        "توابع این قسمت به ترتیب \n",
        "\n",
        "1.    نقاط کنجی عکس پس از اعمال هموگرافی حساب می‌کند.\n",
        "2.   ابعاد تصویر که قرار است وارپ شود را حساب می‌کند. \n",
        "2.   تابع سوم نیز مقدار انتقال مورد نیاز برای دیده شدن تصویر را حساب می‌کند.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAs8M4_yPPnb"
      },
      "source": [
        "def masking(im):\n",
        "    isNotEmpty = False\n",
        "    mask = np.zeros((im.shape[0], im.shape[1]))\n",
        "    for i in range(im.shape[0]):\n",
        "        for j in range(im.shape[1]):\n",
        "            if im[i][j][0] != 0 or im[i][j][1] != 0 or im[i][j][2] != 0:\n",
        "                mask[i][j] = 1\n",
        "                isNotEmpty = True\n",
        "    return mask, isNotEmpty\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKj64nMQPUge"
      },
      "source": [
        "در این تابع ماسک عکس یعنی نقاطی که در آن سیاه نیست را حساب می‌کنیم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqS_wY9cPbeg"
      },
      "source": [
        "# im1 is under im2\n",
        "\n",
        "def simple_merge(im1, im2):\n",
        "    im = np.zeros((im1.shape[0], im1.shape[1], 3))\n",
        "    mask1, _ = masking(im1)\n",
        "    mask2, _ = masking(im2)\n",
        "    for i in range(im1.shape[0]):\n",
        "        for j in range(im1.shape[1]):\n",
        "            if mask1[i][j] == 1 and mask2[i][j] == 0:\n",
        "                im[i][j] = im1[i][j]\n",
        "            elif mask2[i][j] == 1:\n",
        "                im[i][j] = im2[i][j]\n",
        "    return im\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKntRBFDP1xN"
      },
      "source": [
        "این تابع تنها دو عکس را روی هم می‌اندازد. ابتدا ماسک را برای هر دو حساب می‌کند و نقاطی که برای اولی در ماسک هست را هم‌رنگ آن قرار می‌دهد و سپس نقاطی که برای عکس دوم سیاه نیست را هم‌رنگ آن نقطه در عکس دوم قرار می‌دهد. \n",
        "و درنتیجه عکس دوم روی عکس اول قرار می‌گیرد.(قسمت‌های مشترک)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl7g87rDPefE"
      },
      "source": [
        "\n",
        "def dp_merge(im1, im2):\n",
        "    s0, s1 = im1.shape[0], im1.shape[1]\n",
        "    im = np.zeros((s0, s1, 3))\n",
        "    shared = np.zeros((s0, s1))\n",
        "    mask1, _ = masking(im1)\n",
        "    mask2, _ = masking(im2)\n",
        "    for i in range(s0):\n",
        "        for j in range(s1):\n",
        "            shared[i, j] = 256\n",
        "            if mask1[i, j] == 1 and mask2[i, j] == 0:\n",
        "                im[i, j] = im1[i, j]\n",
        "            elif mask2[i, j] == 1 and mask1[i, j] == 0:\n",
        "                im[i, j] = im2[i, j]\n",
        "            elif mask2[i, j] == 1 and mask1[i, j] == 1:\n",
        "                a1, a2 = im1[i, j], im2[i, j]\n",
        "                shared[i, j] = np.sqrt(np.sum((a1.astype('float64') - a2.astype('float64')) ** 2))\n",
        "    path = find_path(shared, s0, s1)\n",
        "    while len(path) > 0:\n",
        "        p = path.pop()\n",
        "        for j in range(s1 - 1):\n",
        "            if j < p[1] and mask1[p[0], j] == 1:\n",
        "                im[p[0], j] = im1[p[0], j]\n",
        "            elif j >= p[1] and mask2[p[0], [j]] == 1:\n",
        "                im[p[0], j] = im2[p[0], j]\n",
        "    return im\n",
        "\n",
        "\n",
        "def find_path(shared, s0, s1):\n",
        "    dp = np.zeros((s0, s1))\n",
        "    pth = np.zeros((s0, s1))\n",
        "    for i in range(s0 - 1):\n",
        "        for j in range(s1 - 1):\n",
        "            mn = min(min(dp[i - 1, j - 1], dp[i - 1, j + 1]), dp[i - 1, j])[0][0]\n",
        "            if mn == dp[i - 1, j - 1]:\n",
        "                pth[i, j] = -1\n",
        "            elif mn == dp[i - 1, j + 1]:\n",
        "                pth[i, j] = 1\n",
        "            elif mn == dp[i - 1, j]:\n",
        "                pth[i, j] = 0\n",
        "\n",
        "            dp[i, j] = shared[i, j] + mn\n",
        "            if dp[i, j] == 0:\n",
        "                dp[i, j] = 10000 + mn\n",
        "            dp[i, 0] = 1000000 + mn\n",
        "            dp[i, s1 - 1] = 1000000 + mn\n",
        "    dp_min = 10000000000\n",
        "    i, j = s0 - 2, s1 - 2\n",
        "\n",
        "    for n in range(1, j):\n",
        "        if dp_min > dp[i, n] != 0:\n",
        "            dp_min = dp[i, n]\n",
        "            j = n\n",
        "\n",
        "    masir = list()\n",
        "    while len(masir) < s0 - 2:\n",
        "        j += int(pth[i, j])\n",
        "        i -= 1\n",
        "        masir.append([i, j])\n",
        "    return masir\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0jj4aDNP026"
      },
      "source": [
        "در این قسمت ادغام عکس‌ها به روش دیپی را انجام می‌دهیم.\n",
        "در تابع اول قسمت‌هایی که به صورت جداگانه هر عکس در آن رنگ دارد را قرار می‌دهیم سپس قسمتی که مشترک است را گرفته و در آن اختلاف هر پیکسل آن در دو عکس را قرار می‌دهیم و سپس آن را به تابع دوم می‌دهیم. در تابع دوم به این صورت عمل می‌کنیم که یک آرایه دیپی می‌گیریم و برای هر نقطه حساب می‌کنیم که از چه مسیری بالای آن نقطه به آن برویم که هزینه مینیمم شود. \n",
        "پس از آن روی نقاط سطر آخر فور زده و مقدار مینیمم مسیر را پیدا کرده و سپس با استفاده از آرایه پث که حرکت قبلی هر خانه را در آن گذاشته‌ایم مسیری که از بالا به نقطه مینیمم پایینی می‌رسد را پیدا کرده و به تابع مرج پاس می‌دهیم. در ادامه نیز روی نقاط پث فور زده و همه‌ی پیکسل‌های پیش از آن را برابر عکس اول و بعد از آن را برابر عکس دوم قرار می‌دهیم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk6IUH74V_Y4"
      },
      "source": [
        "\n",
        "def correct_border(arr1, arr2):\n",
        "    s0, s1 = arr1.shape[0], arr1.shape[1]\n",
        "    im = np.zeros((s0, s1, 3))\n",
        "    for i in range(s0):\n",
        "        for j in range(s1):\n",
        "            if arr2[i, j, 0] != 0 or arr2[i, j, 1] != 0 or arr2[i, j, 2] != 0:\n",
        "                im[i, j] = arr1[i, j]\n",
        "    return im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlQ6lzSwWANl"
      },
      "source": [
        "برای قسمت دوم سوال نیز این تابع را زدم. در این قسمت از \n",
        "\n",
        "borderMode=cv2.BORDER_REPLICATE\n",
        "\n",
        "در ساختن پانوراما استفاده کردم که این حالت مرز‌ها کشیده می‌شوند و مرج تمیزتری درمی‌آید اما مرزها خراب می‌مانند. به همین خاطر یکبار با حالت ساده همه عکس‌ها را به صورت ساده روی هم انداختم و هم‌چنین عکس‌ها را با این حالت به صورت دیپی مرج کردم و برای درست کردن مرز عکس‌ها از مرز عکسی که به صورت ساده مرج کردم استفاده نمودم و پانوراما را بدست آوردم\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c_iUmwSWv5e"
      },
      "source": [
        "\n",
        "\n",
        "def writeIm(arr, name, fldr=''):\n",
        "    imwrite(fldr + '/' + name + '.jpg', arr)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZm7XPnMWz_o"
      },
      "source": [
        "این تابع نیز عکس‌ها را سیو می‌کند."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d79_ysHdW2is"
      },
      "source": [
        "\n",
        "# find homography for key frames\n",
        "\n",
        "h_450 = find_hom(des_ref=des450, des_minor=des450, kp_ref=kp450, kp_minor=kp450)\n",
        "\n",
        "h_270 = find_hom(des_ref=des450, des_minor=des270, kp_ref=kp450, kp_minor=kp270)\n",
        "\n",
        "h_630 = find_hom(des_ref=des450, des_minor=des630, kp_ref=kp450, kp_minor=kp630)\n",
        "\n",
        "h_90 = find_hom(des_ref=des270, des_minor=des90, kp_ref=kp270, kp_minor=kp90)\n",
        "h_90 = h_270 @ h_90\n",
        "\n",
        "h_810 = find_hom(des_ref=des630, des_minor=des810, kp_ref=kp630, kp_minor=kp810)\n",
        "h_810 = h_630 @ h_810\n",
        "\n",
        "h_1 = find_hom(des_ref=des90, des_minor=des1, kp_ref=kp90, kp_minor=kp1)\n",
        "h_1 = h_90 @ h_1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA7ZYu5wW5to"
      },
      "source": [
        "در این قسمت هموگرافی فریم‌های کلیدی را حساب کردم.\n",
        "هم‌چنین هموگرافی فریم اول را برای انتقال در قسمت سوم سوال حساب نمودم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSphEje1XJE6"
      },
      "source": [
        "\n",
        "# warped rectangle\n",
        "\n",
        "a, b = 1 / 3, 2 / 3\n",
        "pts = np.array([a * width, a * height, a * width, b * height, b * width, b * height, b * width, a * height], np.int32)\n",
        "pts = pts.reshape((-1, 1, 2))\n",
        "\n",
        "color = (150, 200, 50)\n",
        "thickness = 4\n",
        "\n",
        "rect_450 = polylines(im450, [pts], isClosed=True, color=color, thickness=thickness)\n",
        "writeIm(arr=rect_450, name='res01-450-rect')\n",
        "\n",
        "H270_inv = inv(h_270)\n",
        "rect = polylines(np.zeros((height, width, 3)), [pts], isClosed=True, color=color, thickness=thickness)\n",
        "warped_rect = warpPerspective(rect, H270_inv, (width, height))\n",
        "\n",
        "rect_270 = simple_merge(img270, warped_rect)\n",
        "writeIm(arr=rect_270, name='res02-270-rect')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djZziOEyXPhH"
      },
      "source": [
        "در این قسمت از کد یک مستطیل به طول 1/3 عکس در وسط فریم 450 کشیدم و سپس مقدار وارون نگاشت هموگرافی 270 را حساب نموده و  تحت آن مستطیل را وارپ کردم. سپس با مرج ساده مستطیل وارپ شده را روی فریم 270 انداختم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufh9mBtbXv_6"
      },
      "source": [
        "\n",
        "T_270 = trans(h_270)\n",
        "H270 = T_270 @ h_270\n",
        "\n",
        "H450 = T_270 @ h_450\n",
        "d = dim(H450)\n",
        "dim270_450 = (d[0], d[1])\n",
        "\n",
        "warped_270 = warpPerspective(img270, H270, dim270_450)\n",
        "warped_450 = warpPerspective(img450, H450, dim270_450)\n",
        "\n",
        "panorama_270_450 = simple_merge(warped_270, warped_450)\n",
        "writeIm(arr=panorama_270_450, name='res03-270-450-panorama')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvAwqnFGX4fk"
      },
      "source": [
        "در این قسمت نیز فریم 270 را تحت هموگرافی به فریم 450 وارپ کردم.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDVh8_gDYPio"
      },
      "source": [
        "T = trans(h_90)\n",
        "H90 = T @ h_90\n",
        "H270 = T @ h_270\n",
        "H450 = T @ h_450\n",
        "H630 = T @ h_630\n",
        "H810 = T @ h_810\n",
        "d = dim(H810)\n",
        "dim_panorama = (d[0] + 200, d[1] + 100)\n",
        "\n",
        "####\n",
        "warped_90 = warpPerspective(img90, H90, dim_panorama)\n",
        "warped_270 = warpPerspective(img270, H270, dim_panorama)\n",
        "warped_450 = warpPerspective(img450, H450, dim_panorama)\n",
        "warped_630 = warpPerspective(img630, H630, dim_panorama)\n",
        "warped_810 = warpPerspective(img810, H810, dim_panorama)\n",
        "\n",
        "panorama_90_270 = simple_merge(warped_90, warped_270)\n",
        "panorama_270_450 = simple_merge(panorama_90_270, warped_450)\n",
        "panorama_630_450 = simple_merge(panorama_270_450, warped_630)\n",
        "panorama_0 = simple_merge(panorama_630_450, warped_810)\n",
        "\n",
        "####\n",
        "warped_90_1 = warpPerspective(img90, H90, dim_panorama, borderMode=cv2.BORDER_REPLICATE)\n",
        "warped_270_1 = warpPerspective(img270, H270, dim_panorama, borderMode=cv2.BORDER_REPLICATE)\n",
        "warped_450_1 = warpPerspective(img450, H450, dim_panorama, borderMode=cv2.BORDER_REPLICATE)\n",
        "warped_630_1 = warpPerspective(img630, H630, dim_panorama, borderMode=cv2.BORDER_REPLICATE)\n",
        "warped_810_1 = warpPerspective(img810, H810, dim_panorama, borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "panorama_90_270_1 = dp_merge(warped_90_1, warped_270_1)\n",
        "panorama_270_450_1 = dp_merge(panorama_90_270_1, warped_450_1)\n",
        "panorama_630_450_1 = dp_merge(panorama_270_450_1, warped_630_1)\n",
        "panorama_1 = dp_merge(panorama_630_450_1, warped_810_1)\n",
        "\n",
        "####\n",
        "panorama = correct_border(panorama_1, panorama_0)\n",
        "\n",
        "writeIm(arr=panorama, name='res04-key-frames-panorama')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0Wq3CNkd6Cq"
      },
      "source": [
        "در این قسمت وارپ فریم‌های کلیدی را به دو صورت حساب می‌کنیم. در حالت اول به صورت ساده وارپ می‌کنیم و به اندازه انتقال فریم 90 همه را انتقال می‌دهیم که همه در یک صفحه قرار بگیرند. \n",
        "سپس برای همه‌ی فریم‌ها در حالتی که مرز رپلیکیت باشد وارپ می‌کنیم. سپس وارپ‌شده‌های اولی را به صورت ساده روی هم می‌اندازیم که مرز کلی مشخص شود. و از وارپ‌شده‌های دومی پانوراما به روش دیپی درست می‌کنم. سپس با تابع کارکت بردر مرز پانوراما را درست می‌کنیم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwrBq9ufe0Ic"
      },
      "source": [
        "\n",
        "T_panorama = trans(h_1)\n",
        "dim_ref_pln = [0, 0]\n",
        "homos = list()\n",
        "Homs = list()\n",
        "for n in range(901):\n",
        "    filename = folder + filenames[n]\n",
        "    img = imread(filename)\n",
        "    kp, des = sift.detectAndCompute(img, None)\n",
        "    h_ref = None\n",
        "    d_ref, k_ref = None, None\n",
        "    if n <= 180:\n",
        "        d_ref, k_ref = des90, kp90\n",
        "        h_ref = h_90\n",
        "    elif 180 < n <= 360:\n",
        "        d_ref, k_ref = des270, kp270\n",
        "        h_ref = h_270\n",
        "    elif 360 < n <= 540:\n",
        "        d_ref, k_ref = des450, kp450\n",
        "        h_ref = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "    elif 540 < n <= 720:\n",
        "        d_ref, k_ref = des630, kp630\n",
        "        h_ref = h_630\n",
        "    else:\n",
        "        d_ref, k_ref = des810, kp810\n",
        "        h_ref = h_810\n",
        "    hom = find_hom(des_ref=d_ref, des_minor=des, kp_ref=k_ref, kp_minor=kp)\n",
        "    hom = h_ref @ hom\n",
        "    homos.append(hom)\n",
        "    Hom = T_panorama @ hom\n",
        "    Homs.append(Hom)\n",
        "    file_hom = open(\"Homography.txt\", \"a\")\n",
        "    file_hom.write('\\'' + 'homography' + str(n) + ':' + '\\'' + str(hom))\n",
        "\n",
        "dim_ref_pln = dim(Homs.pop())\n",
        "# l = len(Homs)\n",
        "\n",
        "for m in range(900):\n",
        "    n = 900 - m\n",
        "    H = Homs.pop()\n",
        "    filename = folder + filenames[n]\n",
        "    img = imread(filename)\n",
        "    warped = warpPerspective(img, H, (dim_ref_pln[0], dim_ref_pln[1]))\n",
        "\n",
        "    writeIm(arr=warped, name='img0' + str(n), fldr='reference-plane')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XfzER4yEdHL"
      },
      "source": [
        "در این قسمت هموگرافی فریم1 به فریم450 را که پیش‌تر حساب کردیم، انتقال را از روی آن محاسبه می‌کنیم. سپس روی تعداد فریم‌های ویدیو فور می‌زنیم (900تای اول)، فریم‌ها را 180تا 180تا جدا می‌کنیم و هموگرافی به نزدیک‌ترین فریم کلیدی را حساب کرده و سپس به صفحه مرجع می‌بریم. \n",
        "نگاشت‌های هموگرافی را در یک فایل می‌نویسیم که در قسمت‌های بعدی از آن‌ها استفاده کنیم.\n",
        "فریم‌های بدست آمده را به وسیله \n",
        "\n",
        "ffmpeg\n",
        "\n",
        "به صورت ویدیو درآوردم. هم‌چنین ویدیوی اصلی احتمالا به دلیل کیفیت بالا با لگ در لپتاپ من به اجرا می‌شد به همین علت برای اطمینان طول و عرض آن را نصف کردم و در فایلی دیگر \n",
        "\n",
        "‫‪res05-reference-plane‬‬(low-res).mp4\n",
        "\n",
        "در نتایج قرار دادم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAp2k-QNuM43"
      },
      "source": [
        "\n",
        "homography_list = []\n",
        "homography_inv_list = []\n",
        "\n",
        "file_content = ''\n",
        "\n",
        "with open('hom.txt') as file:\n",
        "    file_content = file.read()\n",
        "\n",
        "\n",
        "def convert_line_to_numbers(line_of_file):\n",
        "    line_of_file = line_of_file.replace('[', '').replace(']', '')\n",
        "    numbers = []\n",
        "    for number in line_of_file.split(' '):\n",
        "        try:\n",
        "            numbers.append(float(number))\n",
        "        except:\n",
        "            continue\n",
        "    return numbers\n",
        "\n",
        "\n",
        "line_by_line = file_content.split('\\n')\n",
        "h = []\n",
        "line1, line2, line3 = convert_line_to_numbers(line_by_line[0]), convert_line_to_numbers(\n",
        "    line_by_line[1]), convert_line_to_numbers(line_by_line[2])\n",
        "h.append(line1)\n",
        "h.append(line2)\n",
        "h.append(line3)\n",
        "M = (np.array(h, dtype=np.float32))\n",
        "T = trans(M)\n",
        "for a in range(0, len(line_by_line) - 1, 3):\n",
        "    h = []\n",
        "    line1 = convert_line_to_numbers(line_by_line[a])\n",
        "    line2 = convert_line_to_numbers(line_by_line[a + 1])\n",
        "    line3 = convert_line_to_numbers(line_by_line[a + 2])\n",
        "    h.append(line1)\n",
        "    h.append(line2)\n",
        "    h.append(line3)\n",
        "    M = np.array(h, dtype=np.float32)\n",
        "    homography_list.append(M)\n",
        "\n",
        "for h in homography_list:\n",
        "    H = T @ h\n",
        "    h_inv = np.linalg.inv(H)\n",
        "    homography_inv_list.append(h_inv)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BDwFiI7va8D"
      },
      "source": [
        "در این قسمت از کد از فایلی که پیش‌تر در آن هموگرافی‌ها را ذخیره کرده بودم، آن‌ها را می‌خوانم. البته اگر کد را یک‌سره و بدون وقفه ران کنیم نیاز به این قسمت نیست. بیشتر برای اطمینان خاطر و جلوگیری از دوباره کاری بود.\n",
        "در فور پایانی نیز معکوس هموگرافی‌ها را برای قسمت پنجم سوال حساب کرده و در یک لیست نگه داشتم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHYn_LbQHpET"
      },
      "source": [
        "folder = 'reference-plane/img0'\n",
        "im = imread(folder + str(1) + '.jpg')\n",
        "dim_bg = [im.shape[0], im.shape[1]]\n",
        "v, u = 5, 5\n",
        "panorama_bg = np.zeros((dim_bg[0],dim_bg[1],3))\n",
        "x, y = int(dim_bg[0] / v), int(dim_bg[1] / u)\n",
        "for i in range(v + 1):\n",
        "    for j in range(u + 1):\n",
        "        parts = []\n",
        "        for n in range(1, 900):\n",
        "            # img = imread(folder + filenames[n])\n",
        "            # M = homography_list[n]\n",
        "            # warp = warpPerspective(img, M, dim_bg)\n",
        "            # part = warp[x * i:x * (i + 1), y * j:y * (j + 1), :].copy()\n",
        "            img = imread(folder + str(n) + '.jpg')\n",
        "            part = img[x * i:x * (i + 1), y * j:y * (j + 1), :].copy()\n",
        "\n",
        "            if i == v and j == u:\n",
        "                part = img[x * i:, :, :].copy()\n",
        "            elif j == u and i == 0:\n",
        "                part = img[:, j * y:, :].copy()\n",
        "\n",
        "            parts.append(np.ma.array(part, mask=(part == 0)))\n",
        "            # writeIm(part, 'part' + str(n), 'parts')\n",
        "        a = np.ma.median(np.ma.array(parts), axis=0).astype('uint8')\n",
        "        if i == v and j == u:\n",
        "            panorama_bg[x * i:, :, :] = a.copy()\n",
        "        elif j == u and i == 0:\n",
        "            panorama_bg[:, j * y:, :] = a.copy()\n",
        "        else:\n",
        "            panorama_bg[x * i:x * (i + 1), y * j:y * (j + 1), :] = a.copy()\n",
        "\n",
        "        writeIm(a, 'part' + str(i) + str(j), 'masks')\n",
        "        writeIm(panorama_bg, 'pano' + str(i) + str(j), 'masks')\n",
        "\n",
        "writeIm(panorama_bg, 'res06-background-panorama')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWXxlLjkj5AM"
      },
      "source": [
        "در این قسمت از کد که برای قسمت ۴ام زده شده هر عکس بدست آمده در قسمت ۳ را به ۲۵ قطعه تقسیم می‌کنیم، هر هر قطعه را در تمامی عکس‌ها گرفته و در یک لیست قرار می‌دهیم. سپس با استفاده از نامپای ابتدا قسمت‌های سیاه را حذف می‌کنیم.\n",
        "در قسمتی که \n",
        "\n",
        "np.ma.array(part, mask=(part == 0))\n",
        "\n",
        "را زدیم قسمت‌های سیاه را - می‌کند و در نتیجه در میانه گیری به حساب نمی‌آیند.\n",
        "سپس تمامی این قسمت‌ها را از تمامی عکس‌ها گرفته و میانه می‌گیریم و در یک عکس به ابعاد عکس‌ وارپ شده قرار می‌دهیم. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UaCABITj4Fb"
      },
      "source": [
        "panorama_bg = imread('res06-background-panorama.jpg')\n",
        "h_inv_last = homography_inv_list[len(homography_inv_list) - 1]\n",
        "for n in range(len(homography_inv_list)):\n",
        "    h_inv = homography_inv_list[n]\n",
        "\n",
        "    img = cv2.warpPerspective(panorama_bg, h_inv, (width, height))\n",
        "    writeIm(img, 'bg0' + str(n), 'background-frames')\n",
        "\n",
        "    img2 = cv2.warpPerspective(panorama_bg, h_inv, (int(width * 1.5), height))\n",
        "    writeIm(img2, 'bg0' + str(n), 'background-frames-wider')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzBqDaaHxpyx"
      },
      "source": [
        "در این قسمت از کد با استفاده از معکوس هموگرافی که پیش‌تر آن را محاسبه کردیم، پانورامای پیش‌زمینه که در قسمت قبل محاسبه کردیم را وارپ می‌کنیم به در ابعاد فریم‌های ویدیوی خام. هم‌چنین در دو خط آخر تصویر پانوراما را به ابعاد ۵۰٪ پهن‌تر وارپ کردم که این جواب قسمت ۷ سوال است. سپس با استفاده از \n",
        "\n",
        "ffmpeg\n",
        "\n",
        "ویدیوی حاصل از این فریم‌ها را درست کردم."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRAAF72fIj2Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}